model_config:
  name: Qwen/Qwen3-8B
  batch_size: 8192
  rope_scaling:
    rope_type: yarn
    factor: 4.0
    original_max_position_embeddings: 32768
  sampling_params:
    n: 1
    max_tokens: 1000
    top_p: 0.8
    top_k: 20
    temperature: 0.7
  enable_thinking: false
rag_config:
  rag_type: none
  data_path: dataset/wildchat_aqa_with_embedding_and_gpt_generated_query
  max_context_token_count: 127000
  prompt_template_path: prompts/eval_wildchat_aqa_prompt_no_context_rank.md
