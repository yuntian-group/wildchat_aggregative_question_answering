model_config:
  name: google/gemma-3-4b-it
  batch_size: 1024
  sampling_params:
    n: 1
    max_tokens: 2000
    top_p: 0.95
    top_k: 64
    temperature: 1.0
query_generation_model_config:
  name: gpt-4.1-mini
  batch_size: 400
  request_mode: offline_batch
  rpm_limit: 500
  tpm_limit: 200000
  sampling_params:
    temperature: 0.5
    top_p: 0.5
    response_format:
      type: json_object
rag_config:
  rag_type: vector
  data_path: dataset/wildchat_aqa_sampled_subset_with_embedding_and_gpt_generated_query
  max_context_token_count: 127000
  topk: 100
  prompt_template_path: prompts/eval_wildchat_aqa_prompt_rank.md
  elasticsearch_index_name: wildchat_aqa_document
  elasticsearch_host_name: localhost:9200
